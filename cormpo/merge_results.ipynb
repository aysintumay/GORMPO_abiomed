{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\n\n# Define base directories\nbase_dir = Path('/home/ubuntu/GORMPO_abiomed/cormpo/figures')\nmethods = {\n    'VAE': 'vae',\n    'KDE': 'kde',\n    'RealNVP': 'realnvp',\n    'Diffusion': 'diffusion',\n    'NeuralODE': 'neuralode'\n}\n\n# Read all results\nresults_by_dataset = {}\n\nfor method_name, method_dir in methods.items():\n    method_path = base_dir / method_dir\n    if not method_path.exists():\n        print(f\"Method path not found: {method_path}\")\n        continue\n\n    # Check if summary_results.json exists directly in method directory (flat structure)\n    direct_results_file = method_path / 'summary_results.json'\n    if direct_results_file.exists():\n        print(f\"Found direct results: {method_path}\")\n        with open(direct_results_file, 'r') as f:\n            data = json.load(f)\n\n        # Use 'abiomed' as the default dataset name for flat structure\n        dataset_name = 'abiomed'\n        if dataset_name not in results_by_dataset:\n            results_by_dataset[dataset_name] = {}\n\n        results_by_dataset[dataset_name][method_name] = data\n        continue\n\n    # Otherwise, look for dataset subdirectories\n    for dataset_dir in method_path.iterdir():\n        if dataset_dir.is_dir():\n            dataset_name = dataset_dir.name\n            print(f\"Found dataset dir: {dataset_dir}\")\n            results_file = dataset_dir / 'summary_results.json'\n\n            if results_file.exists():\n                with open(results_file, 'r') as f:\n                    data = json.load(f)\n\n                if dataset_name not in results_by_dataset:\n                    results_by_dataset[dataset_name] = {}\n\n                results_by_dataset[dataset_name][method_name] = data\n\nprint(f\"Found {len(results_by_dataset)} datasets:\")\nfor dataset_name in results_by_dataset:\n    print(f\"  - {dataset_name}: {list(results_by_dataset[dataset_name].keys())}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define colors and markers for each method\nmethod_styles = {\n    'VAE': {'color': '#1f77b4', 'marker': 'o', 'linestyle': '-'},\n    'KDE': {'color': '#ff7f0e', 'marker': 's', 'linestyle': '--'},\n    'RealNVP': {'color': '#2ca02c', 'marker': '^', 'linestyle': '-.'},\n    'Diffusion': {'color': '#d62728', 'marker': 'D', 'linestyle': ':'},\n    'NeuralODE': {'color': '#9467bd', 'marker': 'v', 'linestyle': '-'}\n}\n\n# Create plots for each dataset\nfor dataset_name, methods_data in results_by_dataset.items():\n    print(f\"\\nCreating plots for {dataset_name}...\")\n    \n    # Create figure with 2x3 subplots\n    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n    fig.suptitle(f'{dataset_name}', fontsize=16, fontweight='bold')\n    \n    # Plot 1: Mean Log-Likelihood\n    ax1 = axes[0, 0]\n    for method_name, data in methods_data.items():\n        distances = [d['distance'] for d in data]\n        mean_ll = [d['mean_log_likelihood'] for d in data]\n        style = method_styles[method_name]\n        ax1.plot(distances, mean_ll, label=method_name, \n                color=style['color'], marker=style['marker'], \n                linestyle=style['linestyle'], linewidth=2, markersize=8)\n    \n    ax1.set_xlabel('OOD Distance', fontsize=12)\n    ax1.set_ylabel('Mean Log-Likelihood', fontsize=12)\n    ax1.set_title('Mean Log-Likelihood vs OOD Distance', fontsize=14)\n    ax1.legend(fontsize=11)\n    ax1.grid(True, alpha=0.3)\n    \n    # Plot 2: ROC AUC\n    ax2 = axes[0, 1]\n    for method_name, data in methods_data.items():\n        distances = [d['distance'] for d in data]\n        roc_auc = [d['roc_auc'] for d in data]\n        style = method_styles[method_name]\n        ax2.plot(distances, roc_auc, label=method_name, \n                color=style['color'], marker=style['marker'], \n                linestyle=style['linestyle'], linewidth=2, markersize=8)\n    \n    ax2.set_xlabel('OOD Distance', fontsize=12)\n    ax2.set_ylabel('ROC AUC', fontsize=12)\n    ax2.set_title('ROC AUC vs OOD Distance', fontsize=14)\n    ax2.legend(fontsize=11)\n    ax2.grid(True, alpha=0.3)\n    ax2.set_ylim([0, 1.05])\n    \n    # Plot 3: Accuracy\n    ax3 = axes[0, 2]\n    for method_name, data in methods_data.items():\n        distances = [d['distance'] for d in data]\n        accuracy = [d['accuracy'] for d in data]\n        style = method_styles[method_name]\n        ax3.plot(distances, accuracy, label=method_name, \n                color=style['color'], marker=style['marker'], \n                linestyle=style['linestyle'], linewidth=2, markersize=8)\n    \n    ax3.set_xlabel('OOD Distance', fontsize=12)\n    ax3.set_ylabel('Accuracy', fontsize=12)\n    ax3.set_title('Accuracy vs OOD Distance', fontsize=14)\n    ax3.legend(fontsize=11)\n    ax3.grid(True, alpha=0.3)\n    ax3.set_ylim([0, 1.05])\n    \n    # Plot 4: F1 Score\n    ax4 = axes[1, 0]\n    for method_name, data in methods_data.items():\n        distances = [d['distance'] for d in data]\n        f1_score = [d['f1'] for d in data]\n        style = method_styles[method_name]\n        ax4.plot(distances, f1_score, label=method_name, \n                color=style['color'], marker=style['marker'], \n                linestyle=style['linestyle'], linewidth=2, markersize=8)\n    \n    ax4.set_xlabel('OOD Distance', fontsize=12)\n    ax4.set_ylabel('F1 Score', fontsize=12)\n    ax4.set_title('F1 Score vs OOD Distance', fontsize=14)\n    ax4.legend(fontsize=11)\n    ax4.grid(True, alpha=0.3)\n    ax4.set_ylim([0, 1.05])\n    \n    # Plot 5: Precision\n    ax5 = axes[1, 1]\n    for method_name, data in methods_data.items():\n        distances = [d['distance'] for d in data]\n        precision = [d['precision'] for d in data]\n        style = method_styles[method_name]\n        ax5.plot(distances, precision, label=method_name, \n                color=style['color'], marker=style['marker'], \n                linestyle=style['linestyle'], linewidth=2, markersize=8)\n    \n    ax5.set_xlabel('OOD Distance', fontsize=12)\n    ax5.set_ylabel('Precision', fontsize=12)\n    ax5.set_title('Precision vs OOD Distance', fontsize=14)\n    ax5.legend(fontsize=11)\n    ax5.grid(True, alpha=0.3)\n    ax5.set_ylim([0, 1.05])\n    \n    # Plot 6: Recall\n    ax6 = axes[1, 2]\n    for method_name, data in methods_data.items():\n        distances = [d['distance'] for d in data]\n        recall = [d['recall'] for d in data]\n        style = method_styles[method_name]\n        ax6.plot(distances, recall, label=method_name, \n                color=style['color'], marker=style['marker'], \n                linestyle=style['linestyle'], linewidth=2, markersize=8)\n    \n    ax6.set_xlabel('OOD Distance', fontsize=12)\n    ax6.set_ylabel('Recall', fontsize=12)\n    ax6.set_title('Recall vs OOD Distance', fontsize=14)\n    ax6.legend(fontsize=11)\n    ax6.grid(True, alpha=0.3)\n    ax6.set_ylim([0, 1.05])\n    \n    plt.tight_layout()\n    \n    # Save the figure\n    output_dir = base_dir / 'merged_results'\n    output_dir.mkdir(exist_ok=True)\n    output_file = output_dir / f'{dataset_name}_comparison.png'\n    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n    print(f\"  Saved: {output_file}\")\n    \n    plt.show()\n\nprint(\"\\nAll plots created successfully!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Create a summary table showing key metrics\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for dataset_name, methods_data in results_by_dataset.items():\n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for method_name, data in methods_data.items():\n",
    "        print(f\"\\n  {method_name}:\")\n",
    "        df = pd.DataFrame(data)\n",
    "        # Reorder columns to show key metrics first\n",
    "        cols = ['distance', 'roc_auc', 'accuracy', 'f1_score', 'precision', 'recall', \n",
    "                'mean_log_likelihood', 'id_log_likelihood', 'ood_log_likelihood']\n",
    "        # Only include columns that exist in the data\n",
    "        cols = [c for c in cols if c in df.columns]\n",
    "        df = df[cols]\n",
    "        print(df.to_string(index=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mopo_d4rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}